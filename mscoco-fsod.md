| Method | Venue | Year| Backbone|Detector|Paradigm|Setting| COCO 1/5/10/30-shot AP |Code|
| :-----|:-----:|:-----:|:---:|:---:|:----:|:-----|:-----:|:-----:|
[FS-DETR](https://openaccess.thecvf.com/content/ICCV2023/papers/Bulat_FS-DETR_Few-Shot_DEtection_TRansformer_with_Prompting_and_without_Re-Training_ICCV_2023_paper.pdf)|ICCV| 2023| R50 | DETR | without re-training| FSOD| 7.0/10.9/11.3/-|[-]()
[Ïƒ-ADP](https://openaccess.thecvf.com/content/ICCV2023/papers/Du_s-Adaptive_Decoupled_Prototype_for_Few-Shot_Object_Detection_ICCV_2023_paper.pdf)| ICCV| 2023|R-101|Faster R-CNN|meta-learning|FSOD| -/-/20.3/22.8|[-]()|
[Norm-VAE](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Generating_Features_With_Increased_Crop-Related_Diversity_for_Few-Shot_Object_Detection_CVPR_2023_paper.pdf)| CVPR| 2023|R-101| Faster-RCNN |Fine-tuning|FSOD|9.5/15.9/18.7/22.5 |[-]()
[MetaAug](https://openaccess.thecvf.com/content/CVPR2023/papers/Demirel_Meta-Tuning_Loss_Functions_and_Data_Augmentation_for_Few-Shot_Object_Detection_CVPR_2023_paper.pdf) |CVPR| 2023|R-101| Faster-RCNN |Fine-tuning|FSOD|-/-/24.4/28.0|[-]()
[MetaAug](https://openaccess.thecvf.com/content/CVPR2023/papers/Demirel_Meta-Tuning_Loss_Functions_and_Data_Augmentation_for_Few-Shot_Object_Detection_CVPR_2023_paper.pdf) |CVPR| 2023|R-101| Faster-RCNN |Fine-tuning|FSOD|-/-/18.8/23.4|[-]()
[NIFF](https://openaccess.thecvf.com/content/CVPR2023/papers/Guirguis_NIFF_Alleviating_Forgetting_in_Generalized_Few-Shot_Object_Detection_via_Neural_CVPR_2023_paper.pdf)|CVPR |2023| R-101| Faster-RCNN |Fine-tuning|gFSOD|-/33.1/34.0/34.5|[-]()
[DiGeo](https://openaccess.thecvf.com/content/CVPR2023/papers/Ma_DiGeo_Discriminative_Geometry-Aware_Learning_for_Generalized_Few-Shot_Object_Detection_CVPR_2023_paper.pdf) |CVPR| 2023|  R-101| Faster-RCNN |Fine-tuning|gFSOD|-/-/32.0/33.1|[PyTorch](https://github.com/Phoenix-V/DiGeo)
[ICPE](https://ojs.aaai.org/index.php/AAAI/article/view/25274/25046) |AAAI | 2023| R-101| Faster-RCNN |Fine-tuning|FSOD| -/-/19.3/23.1|[PyTorch](https://github.com/lxn96/ICPE)|
[VFA](https://ojs.aaai.org/index.php/AAAI/article/view/25153/24925)| AAAI | 2023| R-101| Faster-RCNN |Fine-tuning|FSOD| -/-/16.2/18.9|[PyTorch](https://github.com/csuhan/VFA)|
[D&R](https://ojs.aaai.org/index.php/AAAI/article/view/25216/24988) | AAAI | 2023| R-101| Faster-RCNN |Fine-tuning|gFSOD| 6.1/13.9/16.4/20.0|[PyTorch](https://github.com/ZYN-1101/DandR)
[DCFS](https://openreview.net/pdf?id=dVXO3Orjmxk)| NeurIPS | 2022| R-101| Faster-RCNN |Fine-tuning|FSOD| 8.1/16.6/19.5/22.7 |[PyTorch](https://csgaobb.github.io/Projects/DCFS)|
[DCFS](https://openreview.net/pdf?id=dVXO3Orjmxk)| NeurIPS | 2022| R-101| Faster-RCNN |Fine-tuning|gFSOD|6.2/15.7/18.3/21.9 |[PyTorch](https://csgaobb.github.io/Projects/DCFS)|
|[CoCo-RCNN](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136860056.pdf)| ECCV |2022|R-101|Sparse-RCNN| Fine-tuning |FSOD|5.2/-/16.4/19.2|[PyTorch](https://github.com/Phoenix-V/coco-rcnn)|
[FewX](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136790707.pdf)|ECCV|2022| R-50 |Faster R-CNN|Fine-tuning|FSOD|-/15.1/-/-|[PyTorch](https://github.com/fanq15/FewX)|
[MFDC](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136690569.pdf)|ECCV|2022| R-101 |Faster R-CNN|Fine-tuning|FSOD|10.8/16.4/19.4/22.7|[PyTorch](https://github.com/WuShuang1998/MFDC)|
[AcroFOD](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136930661.pdf)|ECCV|2022|-|YOLOv5|Fine-tuning|-|-/-/-/- |[PyTorch](https://github.com/Hlings/AcroFOD)|
[TENET](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136800300.pdf)|ECCV|2022|R-50|-|Fine-tuning|FSOD|-/-/19.1/- |[PyTorch](https://github.com/ZS123-lang/TENET)|
|[MoFSOD](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136800354.pdf)|ECCV|2022|R-50|Faster RCNN|Fine-tuning|-|-/-/-/- |[-](https://github.com/amazon-research/few-shot-object-detection-benchmark)|
|[MRSN](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136800388.pdf)|ECCV|2022|R-101|Faster R-CNN|Fine-tuning|FSOD|-/-/15.7/17.5 |[-](https://github.com/MMatx/MRSN)|
|[KD-DeFRCN](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136700279.pdf)|ECCV|2022|R-101|Faster R-CNN|Fine-tuning|FSOD|-/-/18.9/22.6 |-|
|[DETReg](https://arxiv.org/pdf/2106.04550.pdf) |CVPR|2022|DETReg|Deformable DETR|Fine-tuning|gFSOD|-/-/~~25.0~~/~~30.0~~| [PyTorch](https://github.com/amirbar/DETReg)|
|[Label, Verify, Correct](https://openaccess.thecvf.com/content/CVPR2022/papers/Kaul_Label_Verify_Correct_A_Simple_Few_Shot_Object_Detection_Method_CVPR_2022_paper.pdf)| CVPR |2022|R-101+DINO ViT-S|Faster R-CNN|Fine-tuning|FSOD| -/-/17.8/24.5|[PyTorch](https://github.com/prannaykaul/lvc)|
|[Sylph](https://openaccess.thecvf.com/content/CVPR2022/papers/Yin_Sylph_A_Hypernetwork_Framework_for_Incremental_Few-Shot_Object_Detection_CVPR_2022_paper.pdf)| CVPR |2022|R-50|Faster R-CNN| meta-learning|iFSOD|-/-/-/-|-|
|[FCT](https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Few-Shot_Object_Detection_With_Fully_Cross-Transformer_CVPR_2022_paper.pdf)| CVPR |2022|PVTv2-B2-Li| Faster R-CNN |meta-learning|FSOD|5.6/14.0/17.1/21.4|[PyTorch](https://github.com/GuangxingHan/FCT)|
|[KFSOD](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Kernelized_Few-Shot_Object_Detection_With_Efficient_Integral_Aggregation_CVPR_2022_paper.pdf)| CVPR |2022|R-50|Faster-RCN|meta-learning|FSOD|-/-/18.5/-|[-](https://github.com/ZS123-lang/KFSOD)|
|[Meta-Faster-RCNN](https://arxiv.org/abs/2104.07719)| AAAI |2022|R-101|Faster R-CNN| meta-learning|FSOD|5.1/10.8/12.7/16.6|[PyTorch](https://github.com/GuangxingHan/Meta-Faster-R-CNN)|
|[QA-FewDet](https://arxiv.org/abs/2112.09791)| ICCV |2021|R-101|Faster R-CNN| meta-learning|FSOD|4.9/9.7/11.6/16.5|[PyTorch](https://github.com/GuangxingHan/QA-FewDet)|
|[DeFRCN](https://openaccess.thecvf.com/content/ICCV2021/papers/Qiao_DeFRCN_Decoupled_Faster_R-CNN_for_Few-Shot_Object_Detection_ICCV_2021_paper.pdf) | ICCV | 2021|R-101|Faster R-CNN| Fine-tuning|FSOD|7.7/15.9/18.5/22.6|[PyTorch](https://github.com/er-muyue/DeFRCN)
|[DeFRCN](https://openaccess.thecvf.com/content/ICCV2021/papers/Qiao_DeFRCN_Decoupled_Faster_R-CNN_for_Few-Shot_Object_Detection_ICCV_2021_paper.pdf) | ICCV | 2021|R-101|Faster R-CNN| Fine-tuning|gFSOD|4.8/13.6/16.8/21.2|[PyTorch](https://github.com/er-muyue/DeFRCN)
|[FSOD$^{up}$](https://openaccess.thecvf.com/content/ICCV2021/papers/Wu_Universal-Prototype_Enhancing_for_Few-Shot_Object_Detection_ICCV_2021_paper.pdf)| ICCV |2021|R-101|Faster R-CNN|Fine-tuning|gFSOD|-/-/11.0/15.6|[PyTorch](https://github.com/AmingWu/UP-FSOD)
|[DAnA](https://arxiv.org/pdf/2102.12152.pdf)|TMM|2021|R-50|Faster R-CNN|meta-learning|FSOD|-/-/18.6/21.6|[PyTorch](https://github.com/Tung-I/Dual-awareness-Attention-for-Few-shot-Object-Detection)|
|[FADI](https://proceedings.neurips.cc/paper/2021/file/8a1e808b55fde9455cb3d8857ed88389-Paper.pdf)| NeurIPS |2021|R-101|Faster R-CNN|Fine-tuning|gFSOD| 5.7/10.1/12.2/16.1|[PyTorch](https://github.com/yhcao6/FADI)|
|[SRR-FSD](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Semantic_Relation_Reasoning_for_Shot-Stable_Few-Shot_Object_Detection_CVPR_2021_paper.pdf)|CVPR|2021|R-101|Faster R-CNN|Fine-tuning|FSOD| -/-/11.3/14.7|-|
|[MTFA](https://openaccess.thecvf.com/content/CVPR2021/papers/Ganea_Incremental_Few-Shot_Instance_Segmentation_CVPR_2021_paper.pdf)| CVPR |2021|R-50|Faster R-CNN|Fine-tuning|gFSOD| 2.4/6.6/8.5/-|[PyTorch](https://github.com/danganea/iMTFA)|
|[IMTFA](https://openaccess.thecvf.com/content/CVPR2021/papers/Ganea_Incremental_Few-Shot_Instance_Segmentation_CVPR_2021_paper.pdf)| CVPR |2021|R-50|Faster R-CNN|Fine-tuning|iFSOD| 3.3/6.2/7.1/-|[PyTorch](https://github.com/danganea/iMTFA)|
|[CME](https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Beyond_Max-Margin_Class_Margin_Equilibrium_for_Few-Shot_Object_Detection_CVPR_2021_paper.pdf)|CVPR|2021|YOLO|Meta YOLO|meta-learning|gFSOD|-/-/15.1/16.9|[PyTorch](https://github.com/Bohao-Lee/CME)|
|[DCNet](https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Dense_Relation_Distillation_With_Context-Aware_Aggregation_for_Few-Shot_Object_Detection_CVPR_2021_paper.pdf)|CVPR|2021|R-101|Faster R-CNN|meta-learning|FSOD| -/-/12.8/18.6|[](https://github.com/hzhupku/DCNet)|
|[TIP](https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Transformation_Invariant_Few-Shot_Object_Detection_CVPR_2021_paper.pdf)|CVPR|2021|R-101|Faster R-CNN|meta-learning|FSOD|-/-/16.3/18.3|-|
|[FSCE](https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_FSCE_Few-Shot_Object_Detection_via_Contrastive_Proposal_Encoding_CVPR_2021_paper.pdf)|CVPR|2021|R-101|Faster R-CNN |Fine-tuning|FSOD|-/-/11.1/15.3|[PyTorch](https://github.com/MegviiDetection/FSCE)|
|[Retentive R-CNN](https://openaccess.thecvf.com/content/CVPR2021/papers/Fan_Generalized_Few-Shot_Object_Detection_Without_Forgetting_CVPR_2021_paper.pdf)|CVPR|2021|R-101|R-CNN|Fine-tuning|gFSOD|-/8.3/10.5/13.8|[PyTorch](https://github.com/Megvii-BaseDetection/GFSD)|
|[Halluc](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Hallucination_Improves_Few-Shot_Object_Detection_CVPR_2021_paper.pdf)|CVPR|2021|R-101|Faster R-CNN|Fine-tuning|FSOD|4.4/-/-/-|[-](https://github.com/pppplin/HallucFsDet)
|[FSOD-ARPN-MRD](https://arxiv.org/abs/1908.01998)|CVPR |2020|R-50|Faster R-CNN|meta-learning|MetaTest| -/-/-/-/|[-](https://github.com/fanq15/Few-Shot-Object-Detection-Dataset)|
|[ONCE](https://openaccess.thecvf.com/content_CVPR_2020/papers/Perez-Rua_Incremental_Few-Shot_Object_Detection_CVPR_2020_paper.pdf)|CVPR|2020|ResNet|CentreNet|Meta-learning |iFSOD| -/-/-/-/|-|
|[TFA](https://arxiv.org/abs/2003.06957)| ICML|2020|R-101|Faster R-CNN|Fine-tuning|FSOD|-/-/10.0/13.7|[PyTorch](https://github.com/ucbdrive/few-shot-object-detection)|
|[TFA](https://arxiv.org/abs/2003.06957)| ICML|2020|R-101|Faster R-CNN|Fine-tuning|gFSOD|1.9/7.0/9.1/12.1|[PyTorch](https://github.com/ucbdrive/few-shot-object-detection)|
|[FSDetView](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123620188.pdf)|ECCV|2020|R-101|Faster R-CNN |meta-learning|FSOD|-/-/12.5/14.7|[PyTorch](http://imagine.enpc.fr/~xiaoy/FSDetView/)
|[MPSR](https://arxiv.org/pdf/2007.09384.pdf)| ECCV |2020|R-101|Faster R-CNN| Fine-tuning|FSOD|-/-/9.8/14.1|[PyTorch](https://github.com/jiaxi-wu/MPSR)|
|[NP-RepMet](https://arxiv.org/pdf/2010.11714.pdf)|NeurIPS|2020|R-101| Faster R-CNN + DCN|Fine-tuning|FSOD| -/-/-/-|[MXNet](https://github.com/yang-yk/NP-RepMet)|
[Meta-RCNN](https://dl.acm.org/doi/10.1145/3394171.3413832)| ACM-MM |2020|R-101|Faster R-CNN |Meta-learning |FSOD|-/-/8.7/12.4|-|
