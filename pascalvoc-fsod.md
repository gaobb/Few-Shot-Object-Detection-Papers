| Method | Venue | Year| Backbone|Detector|Paradigm|Setting| Set1 1/2/3/5/10-shot |  Set2 1/2/3/5/10-shot | Set3 1/2/3/5/10-shot |Code|
| :-----|:-----:|:-----:|:---:|:---:|:----:|:-----|:-----:|:-----:|:----:|:-----|
[FS-DETR](https://openaccess.thecvf.com/content/ICCV2023/papers/Bulat_FS-DETR_Few-Shot_DEtection_TRansformer_with_Prompting_and_without_Re-Training_ICCV_2023_paper.pdf)|ICCV| 2023| R50 | DETR | without re-training| FSOD| 45.0 48.5 51.5 52.7 56.1| 37.3 41.3 43.4 46.6 49.0 | 43.8 47.1 50.6 52.1 56.9|[-]()
[Ïƒ-ADP](https://openaccess.thecvf.com/content/ICCV2023/papers/Du_s-Adaptive_Decoupled_Prototype_for_Few-Shot_Object_Detection_ICCV_2023_paper.pdf)| ICCV| 2023|R-101|Faster R-CNN|meta-learning|FSOD|35.9 40.3 49.8 56.8 65.1 | 25.6 30.3 41.7 41.8 50.3 | 33.9 35.6 43.5 47.1 55.9|[-]()|
[Norm-VAE](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Generating_Features_With_Increased_Crop-Related_Diversity_for_Few-Shot_Object_Detection_CVPR_2023_paper.pdf)| CVPR| 2023|R-101| Faster-RCNN |Fine-tuning|FSOD|62.1 64.9 67.8 69.2 67.5| 39.9 46.8 54.4 54.2 53.6 |58.2 60.3 61.0 64.0 65.5|[-]()
[MetaAug](https://openaccess.thecvf.com/content/CVPR2023/papers/Demirel_Meta-Tuning_Loss_Functions_and_Data_Augmentation_for_Few-Shot_Object_Detection_CVPR_2023_paper.pdf) |CVPR| 2023|R-101| Faster-RCNN |Fine-tuning|gFSOD|66.7 69.3 69.8 72.2 72.1| 47.7 55.8 61.8 63.9 63.7 |64.9 65.8 66.2 69.7 70.2|[-]()
[MetaAug](https://openaccess.thecvf.com/content/CVPR2023/papers/Demirel_Meta-Tuning_Loss_Functions_and_Data_Augmentation_for_Few-Shot_Object_Detection_CVPR_2023_paper.pdf) |CVPR| 2023|R-101| Faster-RCNN |Fine-tuning|FSOD|58.4 62.4 63.2 67.6 67.7 | 34.0 43.1 51.0 53.6 54.0 | 55.1 56.6 57.3 62.6 63.7|[-]()
[NIFF](https://openaccess.thecvf.com/content/CVPR2023/papers/Guirguis_NIFF_Alleviating_Forgetting_in_Generalized_Few-Shot_Object_Detection_via_Neural_CVPR_2023_paper.pdf)|CVPR |2023| R-101| Faster-RCNN |Fine-tuning|gFSOD|75.6 76.5 76.7 77.4 76.9 | 70.0 71.4 73.9 74.4 74.0 |74.4 75.8 76.2 76.6 76.7|[-]()
[DiGeo](https://openaccess.thecvf.com/content/CVPR2023/papers/Ma_DiGeo_Discriminative_Geometry-Aware_Learning_for_Generalized_Few-Shot_Object_Detection_CVPR_2023_paper.pdf) |CVPR| 2023|  R-101| Faster-RCNN |Fine-tuning|gFSOD|69.7 70.6 72.4 75.4 76.1 | 67.5 68.4 71.4 71.6 73.6 |68.6 70.9 72.9 74.4 75.0|[PyTorch](https://github.com/Phoenix-V/DiGeo)
[ICPE](https://ojs.aaai.org/index.php/AAAI/article/view/25274/25046) |AAAI | 2023| R-101| Faster-RCNN |Fine-tuning|FSOD| 54.3 59.5 62.4 65.7 66.2| 33.5 40.1 48.7 51.7 52.5| 50.9 53.1 55.3 60.6 60.1|[PyTorch](https://github.com/lxn96/ICPE)|
[VFA](https://ojs.aaai.org/index.php/AAAI/article/view/25153/24925)| AAAI | 2023| R-101| Faster-RCNN |Fine-tuning|FSOD| 57.7 64.6 64.7 67.2 67.4 | 41.4 46.2 51.1 51.8 51.6 | 48.9  54.8 56.6 59.0 58.9| [PyTorch](https://github.com/csuhan/VFA)|
[D&R](https://ojs.aaai.org/index.php/AAAI/article/view/25216/24988) | AAAI | 2023| R-101| Faster-RCNN |Fine-tuning|gFSOD| 41.0 51.7 55.7 61.8 65.4 | 30.7 39.0 42.5 46.6 51.7 | 37.9 47.1 51.7 56.8 59.5|[PyTorch](https://github.com/ZYN-1101/DandR)
[DCFS](https://openreview.net/pdf?id=dVXO3Orjmxk)| NeurIPS | 2022| R-101| Faster-RCNN |Fine-tuning|FSOD| 56.6 59.6 62.9 65.6 62.5| 29.7 38.7 46.2 48.9 48.1| 47.9 51.9 53.3 56.1 59.4|[PyTorch](https://csgaobb.github.io/Projects/DCFS)|
[DCFS](https://openreview.net/pdf?id=dVXO3Orjmxk)| NeurIPS | 2022| R-101| Faster-RCNN |Fine-tuning|gFSOD|45.8 59.1 62.1 66.8 68.0| 31.8 41.7 46.6 50.3 53.7| 39.6 52.1 56.3 60.3 63.3|[PyTorch](https://csgaobb.github.io/Projects/DCFS)|
|[CoCo-RCNN](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136860056.pdf)| ECCV |2022|R-101|Sparse-RCNN| Fine-tuning |FSOD|33.5 44.2 50.2 57.5 63.3 | 25.3 31.0 39.6 43.8 50.1 | 24.8 36.9 42.8 50.8 57.7|[PyTorch](https://github.com/Phoenix-V/coco-rcnn)|
[FewX](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136790707.pdf)|ECCV|2022| R-50 |Faster R-CNN|Fine-tuning|FSOD|40.1 44.2 51.2 62.0 63.0| 33.3 33.1 42.3 46.3 52.3| 36.1 43.1 43.5 52.0 56.0|[PyTorch](https://github.com/fanq15/FewX)|
[MFDC](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136690569.pdf)|ECCV|2022| R-101 |Faster R-CNN|Fine-tuning|FSOD|63.4 66.3 67.7 69.4 68.1| 42.1 46.5 53.4 55.3 53.8 | 56.1 58.3 59.0 62.2 63.7|[PyTorch](https://github.com/WuShuang1998/MFDC)|
[TENET](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136800300.pdf)|ECCV|2022|R-50|-|Fine-tuning|FSOD|46.7 - 55.4 62.3 66.9| 40.3 - 44.7 49.3 52.1| 35.5 - 46.0 54.4 54.6 |[PyTorch](https://github.com/ZS123-lang/TENET)|
|[MRSN](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136800388.pdf)|ECCV|2022|R-101|Faster R-CNN|Fine-tuning|FSOD|47.6 48.6 57.8 61.9 62.6| 31.2 38.3 46.7 47.1 50.6| 35.5 30.9 45.6 54.4 57.4|[-](https://github.com/MMatx/MRSN)|
|[KD-DeFRCN](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136700279.pdf)|ECCV|2022|R-101|Faster R-CNN|Fine-tuning|FSOD|58.2 62.5 65.1  68.2 67.4| 37.6 45.6 52.0 54.6 53.2| 53.8 57.7 58.0 62.4 62.2 |-|
|[Label, Verify, Correct](https://openaccess.thecvf.com/content/CVPR2022/papers/Kaul_Label_Verify_Correct_A_Simple_Few_Shot_Object_Detection_Method_CVPR_2022_paper.pdf)| CVPR |2022|R-101+DINO ViT-S|Faster R-CNN|Fine-tuning|FSOD| 54.5 53.2 58.8 63.2 65.7| 32.8 29.2 50.7 49.8 50.6| 48.4 52.7 55.0 59.6 59.6|[PyTorch](https://github.com/prannaykaul/lvc)|
|[FCT](https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Few-Shot_Object_Detection_With_Fully_Cross-Transformer_CVPR_2022_paper.pdf)| CVPR |2022|PVTv2-B2-Li| Faster R-CNN |meta-learning|FSOD|38.5 49.6 53.5 59.8 64.3| 25.9 34.2 40.1 44.9 47.4| 34.7 43.9 49.3 53.1 56.3|[PyTorch](https://github.com/GuangxingHan/FCT)|
|[KFSOD](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Kernelized_Few-Shot_Object_Detection_With_Efficient_Integral_Aggregation_CVPR_2022_paper.pdf)| CVPR |2022|R-50|Faster-RCN|meta-learning|FSOD|44.6 - 54.4 60.9 65.8 | 37.8 - 43.1 48.1 50.4 | 34.8 - 44.1 52.7 53.9|[-](https://github.com/ZS123-lang/KFSOD)|
|[Meta-Faster-RCNN](https://arxiv.org/abs/2104.07719)| AAAI |2022|R-101|Faster R-CNN| meta-learning|FSOD|43.0 54.5 60.6 66.1 65.4 |27.7 35.5 46.1 47.8 51.4 |40.6 46.4 53.4 59.9 58.6|[PyTorch](https://github.com/GuangxingHan/Meta-Faster-R-CNN)|
|[QA-FewDet](https://arxiv.org/abs/2112.09791)| ICCV |2021|R-101|Faster R-CNN| meta-learning|FSOD|42.4 51.9 55.7 62.6 63.4| 25.9 37.8 46.6 48.9 51.1| 35.2 42.9 47.8 54.8 53.5|[PyTorch](https://github.com/GuangxingHan/QA-FewDet)|
|[DeFRCN](https://openaccess.thecvf.com/content/ICCV2021/papers/Qiao_DeFRCN_Decoupled_Faster_R-CNN_for_Few-Shot_Object_Detection_ICCV_2021_paper.pdf) | ICCV | 2021|R-101|Faster R-CNN| Fine-tuning|FSOD|53.6 57.5 61.5 64.1 60.8 | 30.1 38.1 47.0 53.3 47.9 | 48.4 50.9 52.3 54.9 57.4|[PyTorch](https://github.com/er-muyue/DeFRCN)
|[DeFRCN](https://openaccess.thecvf.com/content/ICCV2021/papers/Qiao_DeFRCN_Decoupled_Faster_R-CNN_for_Few-Shot_Object_Detection_ICCV_2021_paper.pdf) | ICCV | 2021|R-101|Faster R-CNN| Fine-tuning|gFSOD|40.2 53.6 58.2  63.6 66.5 | 29.5 39.7 43.4 48.1 52.8 | 35.0 38.3 52.9 57.7 60.8|[PyTorch](https://github.com/er-muyue/DeFRCN)
|[FSOD$^{up}$](https://openaccess.thecvf.com/content/ICCV2021/papers/Wu_Universal-Prototype_Enhancing_for_Few-Shot_Object_Detection_ICCV_2021_paper.pdf)| ICCV |2021|R-101|Faster R-CNN|Fine-tuning|gFSOD|43.8 47.8 50.3 55.4 61.7 | 31.2 30.5 41.2 42.2 48.3| 35.5 39.7 43.9 50.6 53.5|[PyTorch](https://github.com/AmingWu/UP-FSOD)
|[FADI](https://proceedings.neurips.cc/paper/2021/file/8a1e808b55fde9455cb3d8857ed88389-Paper.pdf)| NeurIPS |2021|R-101|Faster R-CNN|Fine-tuning|gFSOD| 50.3 54.8 54.2 59.3 63.2|30.6 35.0 40.3 42.8 48.0 |45.7 49.7 49.1 55.0 59.6|[PyTorch](https://github.com/yhcao6/FADI)|
|[SRR-FSD](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhu_Semantic_Relation_Reasoning_for_Shot-Stable_Few-Shot_Object_Detection_CVPR_2021_paper.pdf)|CVPR|2021|R-101|Faster R-CNN|Fine-tuning|FSOD| 47.8 50.5 51.3 55.2 56.8 |32.5 35.3 39.1 40.8 43.8 |40.1 41.5 44.3 46.9 46.4|-|
|[CME](https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Beyond_Max-Margin_Class_Margin_Equilibrium_for_Few-Shot_Object_Detection_CVPR_2021_paper.pdf)|CVPR|2021||F-RCNN|meta-learning|gFSOD|41.5 47.5 50.4 58.2 60.9| 27.2 30.2 41.4 42.5 46.8 |34.3 39.6 45.1 48.3 51.5|[PyTorch](https://github.com/Bohao-Lee/CME)|
|[CME](https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Beyond_Max-Margin_Class_Margin_Equilibrium_for_Few-Shot_Object_Detection_CVPR_2021_paper.pdf)|CVPR|2021||Meta-YOLO|meta-learning|gFSOD|17.8 26.1 31.5 44.8 47.5| 12.7 17.4 27.1 33.7 40.0| 15.7 27.4 30.7 44.9 48.8|[PyTorch](https://github.com/Bohao-Lee/CME)|
|[DCNet](https://openaccess.thecvf.com/content/CVPR2021/papers/Hu_Dense_Relation_Distillation_With_Context-Aware_Aggregation_for_Few-Shot_Object_Detection_CVPR_2021_paper.pdf)|CVPR|2021|R-101|Faster R-CNN|meta-learning|FSOD| 33.9 37.4 43.7 51.1 59.6 |23.2 24.8 30.6 36.7 46.6 |32.3 34.9 39.7 42.6 50.7|[](https://github.com/hzhupku/DCNet)|
|[TIP](https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Transformation_Invariant_Few-Shot_Object_Detection_CVPR_2021_paper.pdf)|CVPR|2021|R-101|Faster R-CNN|meta-learning|FSOD|27.7 36.5 43.3 50.2 59.6| 22.7 30.1 33.8 40.9 46.9| 21.7 30.6 38.1 44.5 50.9|
|[FSCE](https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_FSCE_Few-Shot_Object_Detection_via_Contrastive_Proposal_Encoding_CVPR_2021_paper.pdf)|CVPR|2021|R-101|Faster R-CNN |Fine-tuning|FSOD|32.9 44.0 46.8 52.9 59.7| 23.7 30.6 38.4 43.0 48.5 |22.6 33.4 39.5 47.3 54.0|[PyTorch](https://github.com/MegviiDetection/FSCE)|
|[Retentive R-CNN](https://openaccess.thecvf.com/content/CVPR2021/papers/Fan_Generalized_Few-Shot_Object_Detection_Without_Forgetting_CVPR_2021_paper.pdf)|CVPR|2021|R-101|R-CNN|Fine-tuning|gFSOD|71.3 72.3 72.1 74.0 74.6 | 66.8 68.4 70.2 70.7 71.5 |69.0 70.9 72.3 73.9 74.1|[PyTorch](https://github.com/Megvii-BaseDetection/GFSD)|
|[Halluc](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Hallucination_Improves_Few-Shot_Object_Detection_CVPR_2021_paper.pdf)|CVPR|2021|R-101|Faster R-CNN|Fine-tuning|FSOD|47.0 44.9 46.5 54.7 54.7 |26.3 31.8 37.4 37.4 41.2 |40.4 42.1 43.3 51.4 49.6|[-](https://github.com/pppplin/HallucFsDet)
|[TFA](https://arxiv.org/abs/2003.06957)| ICML|2020|R-101|Faster R-CNN|Fine-tuning|FSOD|39.8 36.1 44.7 55.7 56.0|23.5 26.9 34.1 35.1 39.1|30.8 34.8 42.8 49.5 49.8|[PyTorch](https://github.com/ucbdrive/few-shot-object-detection)|
|[FSDetView](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123620188.pdf)|ECCV|2020|R-101|Faster R-CNN |meta-learning|FSOD|24.2 35.3 42.2 49.1 57.4|21.6 24.6 31.9 37.0 45.7|21.2 30.0 37.2 43.8 49.6|[PyTorch](http://imagine.enpc.fr/~xiaoy/FSDetView/)
|[MPSR](https://arxiv.org/pdf/2007.09384.pdf)| ECCV |2020|R-101|Faster R-CNN| Fine-tuning|FSOD|41.7 - 51.4 55.2 61.8| 24.4 - 39.2 39.9 47.8|35.6 - 42.3 48.0 49.7|[PyTorch](https://github.com/jiaxi-wu/MPSR)|
|[NP-RepMet](https://arxiv.org/pdf/2010.11714.pdf)|NeurIPS|2020|R-101| Faster R-CNN + DCN|Fine-tuning|FSOD|37.8 40.3 41.7 47.3 49.4|41.6 43.0 43.4 47.4 49.1| 33.3 38.0 39.8 41.5 44.8|[MXNet](https://github.com/yang-yk/NP-RepMet)|